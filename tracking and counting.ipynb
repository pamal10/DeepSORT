{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85922e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd deep_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easydict\n",
    "from utils.parser import get_config\n",
    "from deep_sort import DeepSort\n",
    "from sort.tracker import Tracker\n",
    "\n",
    "deep_sort_weights = 'deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"C:/Users/Resh/Downloads/peoplecount1/peoplecount1.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "area1=[(312,388),(289,390),(474,469),(497,462)]\n",
    "\n",
    "area2=[(279,392),(250,397),(423,477),(454,469)]\n",
    "#area1=[(312,388),(497,390),(474,469),(497,462)]\n",
    "\n",
    "\n",
    "#area2=[(279,392),(454,450),(423,477),(454,469)]\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(\"C:/Users/Resh/Downloads/peoplecount1/peoplecount1.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video source.\")\n",
    "    \n",
    "\n",
    "# Get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (1020, 500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7180de",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed529d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"coco.txt\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_entering={}\n",
    "entering=set()\n",
    "people_leaving={}\n",
    "leaving=set()\n",
    "frames = []\n",
    "count=0\n",
    "\n",
    "red_color = (0, 0, 255)  # (B, G, R)\n",
    "blue_color = (255, 0, 0)  # (B, G, R)\n",
    "green_color = (0, 255, 0)  # (B, G, R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.resize(frame,(1020,500))\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results = model(frame, device='cpu', classes=0, conf=0.8)\n",
    "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bbox outputs\n",
    "            probs = result.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                #print(\"Class:\", class_name)\n",
    "\n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "            \n",
    "            results1=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "            if results1>=0:\n",
    "                people_entering[track_id]=(x2,y2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            if track_id in people_entering:\n",
    "                results2=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "                if results2>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    entering.add(track_id)\n",
    "                    \n",
    "            #people Leaving\n",
    "            results3=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "            if results3>=0:\n",
    "                people_leaving[track_id]=(x2,y2)\n",
    "                cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            if track_id in people_leaving:\n",
    "                results4=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "                if results4>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (255,0 , 255), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    leaving.add(track_id)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        person_count = len(unique_track_ids)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "            \n",
    "        cv2.polylines(og_frame,[np.array(area1,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('1'),(504,471),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "\n",
    "        cv2.polylines(og_frame,[np.array(area2,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('2'),(466,485),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "    \n",
    "        cv2.putText(og_frame,str(len(entering)-len(leaving)),(60,80),cv2.FONT_HERSHEY_COMPLEX,(0.7),(0,0,255),2)\n",
    "\n",
    "        # Draw person count on frame\n",
    "        cv2.putText(og_frame, f\"Person Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        #cv2.imshow(\"Video\", og_frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "        out.write(og_frame)\n",
    "        cv2.imshow(\"RGB\", og_frame)\n",
    "        if cv2.waitKey(1)&0xFF==27:        \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996cec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 1 car, 1053.1ms\n",
      "Speed: 7.0ms preprocess, 1053.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 car, 678.0ms\n",
      "Speed: 7.0ms preprocess, 678.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 car, 809.1ms\n",
      "Speed: 5.0ms preprocess, 809.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 car, 763.1ms\n",
      "Speed: 5.0ms preprocess, 763.1ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 car, 701.1ms\n",
      "Speed: 6.0ms preprocess, 701.1ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1051.1ms\n",
      "Speed: 5.0ms preprocess, 1051.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 persons, 1 car, 1153.1ms\n",
      "Speed: 29.0ms preprocess, 1153.1ms inference, 12.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1180.1ms\n",
      "Speed: 7.0ms preprocess, 1180.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1039.1ms\n",
      "Speed: 7.0ms preprocess, 1039.1ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[242, 245, 235],\n",
      "        [243, 243, 243],\n",
      "        [204, 203, 205],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[242, 245, 235],\n",
      "        [246, 245, 247],\n",
      "        [118, 117, 119],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[245, 246, 241],\n",
      "        [190, 186, 196],\n",
      "        [ 94,  92,  97],\n",
      "        ...,\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 54,  76,  78],\n",
      "        [ 51,  72,  74],\n",
      "        [ 59,  71,  76],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[ 90,  72,  69],\n",
      "        [ 93,  76,  72],\n",
      "        [ 91,  79,  71],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[ 91,  73,  70],\n",
      "        [ 94,  77,  74],\n",
      "        [ 92,  81,  74],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]]], dtype=uint8)\n",
      "orig_shape: (500, 1020)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 7.0037841796875, 'inference': 1039.0727519989014, 'postprocess': 6.000280380249023}\n",
      "\n",
      "0: 320x640 1 person, 1 car, 1512.1ms\n",
      "Speed: 9.0ms preprocess, 1512.1ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[242, 245, 235],\n",
      "        [243, 243, 243],\n",
      "        [204, 203, 205],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[243, 245, 237],\n",
      "        [246, 245, 247],\n",
      "        [118, 117, 119],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[246, 247, 242],\n",
      "        [190, 186, 196],\n",
      "        [ 94,  92,  97],\n",
      "        ...,\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 71,  81,  85],\n",
      "        [ 76,  84,  88],\n",
      "        [ 79,  81,  88],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[102,  83,  81],\n",
      "        [103,  85,  82],\n",
      "        [100,  88,  81],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[ 99,  81,  78],\n",
      "        [107,  89,  86],\n",
      "        [101,  89,  82],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]]], dtype=uint8)\n",
      "orig_shape: (500, 1020)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 8.994340896606445, 'inference': 1512.1145248413086, 'postprocess': 5.996942520141602}\n",
      "[796, 353]\n",
      "\n",
      "0: 320x640 1 person, 1 car, 929.1ms\n",
      "Speed: 9.0ms preprocess, 929.1ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[242, 245, 235],\n",
      "        [243, 243, 243],\n",
      "        [204, 203, 205],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[243, 245, 237],\n",
      "        [246, 245, 247],\n",
      "        [118, 117, 119],\n",
      "        ...,\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136],\n",
      "        [255, 255, 136]],\n",
      "\n",
      "       [[247, 248, 243],\n",
      "        [190, 186, 196],\n",
      "        [ 94,  92,  97],\n",
      "        ...,\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137],\n",
      "        [255, 255, 137]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 68,  78,  82],\n",
      "        [ 75,  83,  87],\n",
      "        [ 79,  81,  88],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[101,  83,  80],\n",
      "        [102,  84,  81],\n",
      "        [100,  89,  82],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]],\n",
      "\n",
      "       [[ 99,  81,  78],\n",
      "        [107,  89,  86],\n",
      "        [101,  89,  82],\n",
      "        ...,\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227],\n",
      "        [ 81, 170, 227]]], dtype=uint8)\n",
      "orig_shape: (500, 1020)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 9.004354476928711, 'inference': 929.0695190429688, 'postprocess': 4.996299743652344}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[796, 353]\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.resize(frame,(1020,500))\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results=model.predict(frame)\n",
    "        cls=None\n",
    "        conf=None\n",
    "        xyxy=None\n",
    "        xywh=None\n",
    "        \n",
    "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "        people_results = [result for result in results if class_names[int(result.boxes.cls[torch.argmax(result.boxes.conf).item()])] == 'person']\n",
    "        \n",
    "        \n",
    "        for i in people_results:\n",
    "            boxes = i.boxes  # Boxes object for bbox outputs\n",
    "            probs = i.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                #print(\"Class:\", class_name) boxes = result.boxes  # Boxes information\n",
    "    \n",
    "      # Extract bounding boxes for people detections\n",
    "            bboxes_xywh = boxes.xywh.cpu().numpy()  # Assuming xywh format\n",
    "\n",
    "      # Update tracker with person detections (replace your tracker if needed)\n",
    "            tracks = tracker.update(bboxes_xywh,conf, og_frame)  # Update tracker (modify if necessary)\n",
    "\n",
    "    \n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "            \n",
    "            results1=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "            if results1>=0:\n",
    "                people_entering[track_id]=(x2,y2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            if track_id in people_entering:\n",
    "                results2=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "                if results2>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    entering.add(track_id)\n",
    "                    \n",
    "            #people Leaving\n",
    "            results3=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "            if results3>=0:\n",
    "                people_leaving[track_id]=(x2,y2)\n",
    "                cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            if track_id in people_leaving:\n",
    "                results4=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "                if results4>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (255,0 , 255), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    leaving.add(track_id)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "                \n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "                #cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "                #text_color = (0, 0, 0)  # Black color for text\n",
    "                #cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "                #unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        person_count = len(unique_track_ids)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "            \n",
    "        cv2.polylines(og_frame,[np.array(area1,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('1'),(504,471),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "\n",
    "        cv2.polylines(og_frame,[np.array(area2,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('2'),(466,485),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "    \n",
    "        cv2.putText(og_frame,str(len(entering)-len(leaving)),(60,80),cv2.FONT_HERSHEY_COMPLEX,(0.7),(0,0,255),2)\n",
    "\n",
    "        # Draw person count on frame\n",
    "        cv2.putText(og_frame, f\"Person Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        #cv2.imshow(\"Video\", og_frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "        out.write(og_frame)\n",
    "        cv2.imshow(\"RGB\", og_frame)\n",
    "        if cv2.waitKey(1)&0xFF==27:        \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c64bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.resize(frame,(1020,500))\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"yolov8s.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results=model.predict(frame)\n",
    "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bbox outputs\n",
    "            probs = result.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                #print(\"Class:\", class_name)\n",
    "\n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "            \n",
    "            results1=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "            if results1>=0:\n",
    "                people_entering[track_id]=(x2,y2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            if track_id in people_entering:\n",
    "                results2=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "                if results2>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    entering.add(track_id)\n",
    "                    \n",
    "            #people Leaving\n",
    "            results3=cv2.pointPolygonTest(np.array(area1,np.int32),((x2,y2)),False)\n",
    "            if results3>=0:\n",
    "                people_leaving[track_id]=(x2,y2)\n",
    "                cv2.rectangle(og_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            if track_id in people_leaving:\n",
    "                results4=cv2.pointPolygonTest(np.array(area2,np.int32),((x2,y2)),False)\n",
    "                if results4>=0:\n",
    "                    cv2.rectangle(og_frame, (x1, y1), (x2, y2), (255,0 , 255), 2)\n",
    "                    cv2.circle(og_frame,(x2,y2),5,(255,0,255),-1)\n",
    "                    cv2.putText(og_frame, str(track_id), (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    leaving.add(track_id)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        person_count = len(unique_track_ids)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "            \n",
    "        cv2.polylines(og_frame,[np.array(area1,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('1'),(504,471),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "\n",
    "        cv2.polylines(og_frame,[np.array(area2,np.int32)],True,(255,0,0),2)\n",
    "        cv2.putText(og_frame,str('2'),(466,485),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "    \n",
    "        cv2.putText(og_frame,str(len(entering)-len(leaving)),(60,80),cv2.FONT_HERSHEY_COMPLEX,(0.7),(0,0,255),2)\n",
    "\n",
    "        # Draw person count on frame\n",
    "        cv2.putText(og_frame, f\"Person Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        #cv2.imshow(\"Video\", og_frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "        out.write(og_frame)\n",
    "        cv2.imshow(\"RGB\", og_frame)\n",
    "        if cv2.waitKey(1)&0xFF==27:        \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf5d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
